{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from tabulate import tabulate\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Performance metrics of Baseline Models ----------\n",
      "+---------------------------+------------+-------------+----------+------------+\n",
      "| Model                     |   Accuracy |   Precision |   Recall |   F1 Score |\n",
      "+===========================+============+=============+==========+============+\n",
      "| Logistic Regression Model |   0.383982 |    0.442538 | 0.383982 |   0.361685 |\n",
      "+---------------------------+------------+-------------+----------+------------+\n",
      "| Decision Tree Model       |   0.639443 |    0.638721 | 0.639443 |   0.638891 |\n",
      "+---------------------------+------------+-------------+----------+------------+\n",
      "| Random Forest Model       |   0.749604 |    0.749748 | 0.749604 |   0.74886  |\n",
      "+---------------------------+------------+-------------+----------+------------+\n"
     ]
    }
   ],
   "source": [
    "# Initialize baseline models\n",
    "lr_model = LogisticRegression()                                                         # Initialize Logistic Regression model\n",
    "dt_model = DecisionTreeClassifier()                                                     # Initialize Decision Tree Classifier model\n",
    "rf_model = RandomForestClassifier()                                                     # Initialize Random Forest Classifier model\n",
    "\n",
    "# Load training, testing and validation datasets\n",
    "X_train = pd.read_csv('../output_csv_files/X_train.csv')                                # Load training features\n",
    "X_test = pd.read_csv('../output_csv_files/X_test.csv')                                  # Load testing features\n",
    "y_train = pd.read_csv('../output_csv_files/y_train.csv')                                # Load training labels\n",
    "y_test = pd.read_csv('../output_csv_files/y_test.csv')                                  # Load testing labels\n",
    "X_cv = pd.read_csv('../output_csv_files/X_cv.csv')                                      # Load validation features\n",
    "y_cv = pd.read_csv('../output_csv_files/y_cv.csv')                                      # Load validation labels\n",
    "\n",
    "# Train the models\n",
    "lr_model.fit(X_train, y_train)\n",
    "dt_model.fit(X_train, y_train)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on validation set\n",
    "lr_cv_pred = lr_model.predict(X_cv)\n",
    "dt_cv_pred = dt_model.predict(X_cv)\n",
    "rf_cv_pred = rf_model.predict(X_cv)\n",
    "\n",
    "# Computnig accuracy of baseline models\n",
    "lr_accuracy = accuracy_score(y_cv, lr_cv_pred)\n",
    "dt_accuracy = accuracy_score(y_cv, dt_cv_pred)\n",
    "rf_accuracy = accuracy_score(y_cv, rf_cv_pred)\n",
    "\n",
    "# Compute precision of baseline models\n",
    "lr_precision = precision_score(y_cv, lr_cv_pred, average='weighted')\n",
    "dt_precision = precision_score(y_cv, dt_cv_pred, average='weighted')\n",
    "rf_precision = precision_score(y_cv, rf_cv_pred, average='weighted')\n",
    "\n",
    "# Compute recall of baseline models\n",
    "lr_recall = recall_score(y_cv, lr_cv_pred, average='weighted')\n",
    "dt_recall = recall_score(y_cv, dt_cv_pred, average='weighted')\n",
    "rf_recall = recall_score(y_cv, rf_cv_pred, average='weighted')\n",
    "\n",
    "# Compute F1 score of baseline models\n",
    "lr_f1 = f1_score(y_cv, lr_cv_pred, average='weighted')\n",
    "dt_f1 = f1_score(y_cv, dt_cv_pred, average='weighted')\n",
    "rf_f1 = f1_score(y_cv, rf_cv_pred, average='weighted')\n",
    "\n",
    "# Prepare data for tabulation\n",
    "data = [\n",
    "    [\"Logistic Regression Model\", lr_accuracy, lr_precision, lr_recall, lr_f1],\n",
    "    [\"Decision Tree Model\", dt_accuracy, dt_precision, dt_recall, dt_f1],\n",
    "    [\"Random Forest Model\", rf_accuracy, rf_precision, rf_recall, rf_f1]\n",
    "]\n",
    "\n",
    "headers = [\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1 Score\"]\n",
    "\n",
    "# Print the performance metrics in a tabular format\n",
    "print(\"-\"*10, \"Performance metrics of Baseline Models\", \"-\"*10)\n",
    "print(tabulate(data, headers=headers, tablefmt=\"grid\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
